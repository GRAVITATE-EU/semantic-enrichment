#
# ch_information_extraction_app config
#

[datasets]

input_file=artifact-text.json
input_format=sparql_json

output_file_productions=productions.trig
output_file_item_set=association_mining_item_set.txt

# lexicon files (export = '' means skip lexicon creation) (import and export = '' means no lexicon)
export_lexicon_file=bm_lexicon.csv
import_lexicon_file=

import_file_format=json
filename_lemma=ch-gazatteer-names.json
filename_hypernym=ch-gazatteer-hypernym.json
filename_related=ch-gazatteer-related.json

noun_types_ranked=noun_type_CH_ranked_list.txt
noun_types_ch_lexicon=noun_type_CH_lexicon_25Sept2018_MP.csv

#
# semantic mapping patterns
#

semantic_mapping_ch=semantic_mapping_CH.txt

# limit for number of documents before processing stops (-1 for no limit)
max_doc_limit=-1

# limit URIs allowed in corpus [] for no limit
list_allowed_uri=
	[
	#'http://collection.britishmuseum.org/id/object/YCA29458',
	#'http://collection.britishmuseum.org/id/object/GAA76120',
	#'http://collection.britishmuseum.org/id/object/GAA76121',
	#'http://collection.britishmuseum.org/id/object/GAA76467',
	]

[common]

# language code to use
language_codes=['en']

# stanford tagger dir
stanford_tagger_dir=c:\stanford-postagger-full

# stanford dependancy parser dir
stanford_parser_dir=c:\stanford-parser-full

# parser model
model_path=edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz
model_jar=c:\stanford-parser-full\stanford-english-corenlp-2016-10-31-models.jar
model_options=
